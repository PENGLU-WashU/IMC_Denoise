{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script is to integrate DMIR / DeepSNIF analysis from the IMC_denoise package into the steinbock (https://bodenmillergroup.github.io/steinbock/) workflow\n",
    "### Step of steinbock pipeline: after the conversion of mcd into .tiff files \n",
    "\n",
    "### Edited from the example DeepSNiF train/run jupyter notebook script in IMC_denoise\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tp\n",
    "from IMC_Denoise.IMC_Denoise_main.DIMR import DIMR\n",
    "from IMC_Denoise.IMC_Denoise_main.DeepSNiF import DeepSNiF\n",
    "from IMC_Denoise.DeepSNiF_utils.DeepSNiF_DataGenerator import DeepSNiF_DataGenerator\n",
    "\n",
    "if 'generated_patches' in globals():\n",
    "    del generated_patches\n",
    "\n",
    "train_directory = \"C:\\\\Users\\\\......\\\\training_img\" # change this to the directory of your training images \n",
    "Raw_directory = \"C:\\\\Users\\\\......\\\\img\" # change this directory to your directory of pre-denoised tiffs (always ends with \\\\img for steinbock exports).\n",
    "output_directory = \"C:\\\\Users\\\\......\\\\output\" # change this directory to where you want the denoised images to be written to\n",
    "\n",
    "# Make all three directories the same to train on the whole dataset, then overwrite your current files with the denoised versions\n",
    "\n",
    "# The most convenient way to integrate steinbock and IMC_denoise is to have the output directly overwrite the img folder.\n",
    "# This code chunk creates a pre_denoised copy of the img folder if you plan to use the overwrite.\n",
    "# This means if you need to undo/redo the denoising, steinbock will not need to convert the mcd's to tiffs again\n",
    "if Raw_directory == output_directory:    \n",
    "    if os.path.isdir(Raw_directory + \"_pre_denoise\") == False:\n",
    "        shutil.copytree(Raw_directory,(Raw_directory + \"_pre_denoise\"))\n",
    "    else:\n",
    "        print('img_pre_denoise folder already exists, will not copy current img directory')\n",
    "        \n",
    "        \n",
    "# Choose what channels you want to denoise:\n",
    "channel_names = [17,18]     # list of integers corresponding to the channels of interest / channels you want to denoise\n",
    "                            # IMPORTANT! only run channels that you want to denoise with DIMR and DeepSNiF -- examine images first before running\n",
    "                            # if overwriting (raw_directory == output_directory), you cannot directly re-run the same channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53406855",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 0.1: edit IMC_denoise so that it will ingest multi-channle tiffs directly from the directory, instead of requiring the directory structure of the original IMC_denoise package\n",
    "# Edits in this file: ...\\IMC_Denoise\\DeepSNIF_utils\\DeepSniF_DataGenerator.py\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0.2: set up a function that integrates all the training functions of IMC_denoise\n",
    "# Just done here so that the code for iterating through the channels is simpler\n",
    "def DeepSNIF_train(channel_name, n_neighbours = 4, n_iter = 3, window_size = 3, train_epoches = 25, train_initial_lr = 1e-3, \n",
    "                  train_batch_size = 128, pixel_mask_percent = 0.2, val_set_percent = 0.15, loss_function = \"I_divergence\",\n",
    "                  weights_name = None, loss_name = None, weights_save_directory = None, lambda_HF = 3e-6):\n",
    "    '''\n",
    "    Docstring?\n",
    "    '''\n",
    "    DataGenerator = DeepSNiF_DataGenerator(run_type = 'multi_channel_tiff', channel_name = channel_name, ratio_thresh = 0.8,\n",
    "                                           patch_row_size = 64, patch_col_size = 64, row_step = 60, col_step = 60,\n",
    "                                           n_neighbours = n_neighbours, n_iter = n_iter, window_size = window_size)\n",
    "    generated_patches = DataGenerator.generate_patches_from_directory(load_directory = train_directory)\n",
    "    print('The shape of the generated training set for channel ' + str(channel_name)  + ' is ' + str(generated_patches.shape) + '.')\n",
    "    is_load_weights = False # Use the trained model directly. Will not read from saved one.\n",
    "    deepsnif = DeepSNiF(train_epoches = train_epoches, \n",
    "                    train_learning_rate = train_initial_lr,\n",
    "                    train_batch_size = train_batch_size,\n",
    "                    mask_perc_pix = pixel_mask_percent,\n",
    "                    val_perc = val_set_percent,\n",
    "                    loss_func = loss_function,\n",
    "                    weights_name = weights_name,\n",
    "                    loss_name = loss_name,\n",
    "                    weights_dir = weights_save_directory, \n",
    "                    is_load_weights = is_load_weights,\n",
    "                    lambda_HF = lambda_HF)\n",
    "    train_loss, val_loss = deepsnif.train(generated_patches)\n",
    "    return(n_neighbours, n_iter, window_size, train_loss, val_loss, deepsnif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: iterate through the channels, training  and then running for each image\n",
    "if len(channel_names) < 1:  ## if no channel names are specified, all channels are run! Depending on how many channels / how long the training -- that would take a very long time\n",
    "    print('No channels specified! Will denoise all channels in provided .tiffs')\n",
    "    tif = TiffFile(Raw_directory + \"\\\\\" + listdir(Raw_directory)[0])  # reads the first image in the dataset to get the number of channels in the dataset (assumes a consistent number)\n",
    "    channel_number = len(tif.pages)\n",
    "    i = 0\n",
    "    for j in np.range(0,channel_number):\n",
    "        channel_names.append(i)\n",
    "        i += 1\n",
    "for i in channel_names:\n",
    "    n_neighbours, n_iter, window_size, train_loss, val_loss, deepsnif = DeepSNIF_train(i)\n",
    "    for img in os.listdir(Raw_directory):\n",
    "        Img_raw = tp.TiffFile(Raw_directory + \"\\\\\" + img).pages[i].asarray()\n",
    "        Img_DIMR_DeepSNiF = deepsnif.perform_IMC_Denoise(Img_raw, n_neighbours = n_neighbours, n_iter = n_iter, window_size = window_size)\n",
    "        numpy_tiff = tp.imread(Raw_directory + \"\\\\\" + img)\n",
    "        numpy_tiff[i] = Img_DIMR_DeepSNiF\n",
    "        tp.imwrite((output_directory + \"\\\\\" + img),numpy_tiff, photometric='minisblack')\n",
    "\n",
    "# Steinbock should now be able to seemlessly work with the denoised files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
